{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from data import JPXdataModule\n",
    "from models import PortfolioOptimizer, ReturnsDeltaClassifier, VolatilityDeltaClassifier\n",
    "from utils import spread_return_sharpe_from_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "data = JPXdataModule(merge_with_secondary=False)\n",
    "del data\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "data = JPXdataModule(merge_with_secondary=True)\n",
    "del data\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(2):\n",
    "    for i in range(5):\n",
    "\n",
    "        fold = 'CV5{}'.format(i)\n",
    "\n",
    "        data = JPXdataModule(mode='returns_classification', fold=fold, merge_with_secondary=False)\n",
    "        name = 'returns_momentum_' + fold\n",
    "\n",
    "        if os.path.exists('./weights/jpx_'+name+'.ckpt'):\n",
    "\n",
    "            model = ReturnsDeltaClassifier.load_from_checkpoint('./weights/jpx_'+name+'.ckpt', width = data.x.shape[-1])\n",
    "            model.eval()\n",
    "            model.cuda()\n",
    "\n",
    "            outputs = []\n",
    "            outputs_sec = []\n",
    "\n",
    "            for x, x_sec, _, _, _, _ in tqdm(data.all_dataloader()):\n",
    "\n",
    "                outputs.append(torch.sigmoid(model(x.cuda())).detach().cpu())\n",
    "                outputs_sec.append(torch.sigmoid(model(x_sec.cuda())).detach().cpu())\n",
    "\n",
    "            outputs = torch.cat(outputs, dim=0)\n",
    "            outputs_sec = torch.cat(outputs_sec, dim=0)\n",
    "\n",
    "            torch.save(outputs, data.settings['CACHE_DIR'] + 'pred_returns_delta_{}.pt'.format(fold))\n",
    "            torch.save(outputs_sec, data.settings['CACHE_DIR'] + 'pred_returns_delta_{}_sec.pt'.format(fold))\n",
    "\n",
    "            del outputs, outputs_sec\n",
    "\n",
    "            model.cpu()\n",
    "            data.vamos()\n",
    "        else:\n",
    "\n",
    "            model = ReturnsDeltaClassifier(width=data.x.shape[-1])\n",
    "            trainer, callback0, callback1 = get_trainer(name=name, monitor='val_roc_auc', mode='max')\n",
    "            trainer.fit(model, data)\n",
    "\n",
    "            model.cpu()\n",
    "            data.vamos()\n",
    "\n",
    "            # to free cuda data dependences\n",
    "            for optimizer_metrics in trainer.optimizers[0].state.values():\n",
    "                for metric_name, metric in optimizer_metrics.items():\n",
    "                    if torch.is_tensor(metric):\n",
    "                        optimizer_metrics[metric_name] = metric.cpu()\n",
    "\n",
    "            # outputs, outputs_sec, \n",
    "            del callback0, callback1, trainer\n",
    "\n",
    "        del model, data\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(2):\n",
    "    for i in range(5):\n",
    "\n",
    "        fold = 'CV5{}'.format(i)\n",
    "\n",
    "        data = JPXdataModule(mode='volatility_classification', fold=fold, merge_with_secondary=False)\n",
    "        name = 'volatility_momentum_' + fold\n",
    "\n",
    "        if os.path.exists('./weights/jpx_'+name+'.ckpt'):\n",
    "\n",
    "            model = VolatilityDeltaClassifier.load_from_checkpoint('./weights/jpx_'+name+'.ckpt', width = data.x.shape[-1])\n",
    "            model.eval()\n",
    "            model.cuda()\n",
    "\n",
    "            outputs = []\n",
    "            outputs_sec = []\n",
    "\n",
    "            for x, x_sec, _, _, _, _ in tqdm(data.all_dataloader()):\n",
    "\n",
    "                outputs.append(torch.sigmoid(model(x.cuda())).detach().cpu())\n",
    "                outputs_sec.append(torch.sigmoid(model(x_sec.cuda())).detach().cpu())\n",
    "\n",
    "            outputs = torch.cat(outputs, dim=0)\n",
    "            outputs_sec = torch.cat(outputs_sec, dim=0)\n",
    "\n",
    "            torch.save(outputs, data.settings['CACHE_DIR'] + 'pred_volatility_delta_{}.pt'.format(fold))\n",
    "            torch.save(outputs_sec, data.settings['CACHE_DIR'] + 'pred_volatility_delta_{}_sec.pt'.format(fold))\n",
    "\n",
    "            del outputs, outputs_sec\n",
    "\n",
    "            model.cpu()\n",
    "            data.vamos()\n",
    "        else:\n",
    "\n",
    "            model = VolatilityDeltaClassifier(width=data.x.shape[-1])\n",
    "            trainer, callback0, callback1 = get_trainer(name=name, monitor='val_roc_auc', mode='max')\n",
    "            trainer.fit(model, data)\n",
    "\n",
    "            model.cpu()\n",
    "            data.vamos()\n",
    "\n",
    "            # to free cuda data dependences\n",
    "            for optimizer_metrics in trainer.optimizers[0].state.values():\n",
    "                for metric_name, metric in optimizer_metrics.items():\n",
    "                    if torch.is_tensor(metric):\n",
    "                        optimizer_metrics[metric_name] = metric.cpu()\n",
    "\n",
    "            # outputs, outputs_sec, \n",
    "            del callback0, callback1, trainer\n",
    "\n",
    "        del model, data\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "\n",
    "    fold = 'CV5{}'.format(i)\n",
    "\n",
    "    name = 'portfolio_optimization_' + fold\n",
    "\n",
    "    if not os.path.exists('./weights/jpx_'+name+'.ckpt'):\n",
    "\n",
    "        data = JPXdataModule(mode='portfolio_optimization', fold=fold, merge_with_secondary=False)\n",
    "\n",
    "        model = PortfolioOptimizer(width=data.x.shape[-1])\n",
    "        trainer, callback0, callback1 = get_trainer(name=name, monitor='val_sharpe_ratio', mode='max')\n",
    "        trainer.fit(model, data)\n",
    "\n",
    "        model.cpu()\n",
    "        data.vamos()\n",
    "\n",
    "        # to free cuda data dependences\n",
    "        for optimizer_metrics in trainer.optimizers[0].state.values():\n",
    "            for metric_name, metric in optimizer_metrics.items():\n",
    "                if torch.is_tensor(metric):\n",
    "                    optimizer_metrics[metric_name] = metric.cpu()\n",
    "\n",
    "        # outputs, outputs_sec, \n",
    "        del callback0, callback1, trainer\n",
    "\n",
    "        del model, data\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infenrence_time():\n",
    "\n",
    "    print('INFERENCE TIME')\n",
    "\n",
    "    data = JPXdataModule(mode='inference', fold='CV50', merge_with_secondary=False)\n",
    "\n",
    "    with open('./settings.json') as f:\n",
    "        settings = json.load(f)\n",
    "\n",
    "    prices_csv = pd.read_csv(settings['SUPP_DIR'] + 'stock_prices.csv').iloc[:,1:]\n",
    "    financials_csv = pd.read_csv(settings['SUPP_DIR'] + 'financials.csv')\n",
    "\n",
    "    for day in tqdm(np.unique(prices_csv.Date)):\n",
    "\n",
    "        day_prices_csv = prices_csv[prices_csv.Date == day]\n",
    "        day_financials_csv = financials_csv[financials_csv.Date == day]\n",
    "\n",
    "        sample_prediction = pd.DataFrame(day_prices_csv.SecuritiesCode, columns=['SecuritiesCode'])\n",
    "        sample_prediction['Date'] = day_prices_csv.Date.iloc[0]\n",
    "        sample_prediction['Rank'] = 0\n",
    "\n",
    "        for i in range(5):\n",
    "\n",
    "            fold = 'CV5{}'.format(i)\n",
    "\n",
    "            input = data.process_day_for_inference(day_prices_csv, day_financials_csv)\n",
    "            weights = model(input)\n",
    "\n",
    "        ranking = np.zeros(len(sample_prediction))\n",
    "\n",
    "        for i in range(len(sample_prediction)):\n",
    "\n",
    "            sec_id = np.argwhere(data.unique_secus==sample_prediction.iloc[i].SecuritiesCode)\n",
    "\n",
    "            if len(sec_id) == 1:\n",
    "\n",
    "                ranking[i] = weights[0,sec_id.item()].item()\n",
    "\n",
    "        sample_prediction.Rank = ranking\n",
    "        sample_prediction.sort_values(by=['Rank'], ascending=False, inplace=True)\n",
    "        sample_prediction.Rank = np.arange(len(sample_prediction))\n",
    "\n",
    "        sample_prediction.sort_index(ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
